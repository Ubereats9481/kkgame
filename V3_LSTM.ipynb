{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 需要使用高RAM的機器，免費版的colab目前跑不動"
      ],
      "metadata": {
        "id": "QPONMhpLzfVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FLSCBx-4MBP",
        "outputId": "70e92e88-e622-45f9-c359-9a814ebb0eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_IhuBdV4Ktn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bm0w2-v4Nx3"
      },
      "outputs": [],
      "source": [
        "def read_vectors_from_file(file_path): #讀song_id和對應的vector，並處理成一個字典對照表 一個所有vectors 的array\n",
        "    vectors = []\n",
        "    dic = {}\n",
        "    skip_first = True\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            if skip_first:\n",
        "                skip_first = False\n",
        "                continue\n",
        "            # 移除空白字符，然後以逗號分隔\n",
        "            vector_strings = line.strip().split(' ')\n",
        "\n",
        "            if len(vector_strings[0]) < 10:  # not hash code\n",
        "                continue\n",
        "            if vector_strings[0][0:3] in [\"com\", \"gen\", \"lyr\", \"prd\", \"ttl\"]:\n",
        "                continue\n",
        "\n",
        "            # 將字符串轉換為浮點數\n",
        "            vector = [float(num) / 10 for num in vector_strings[1:]]\n",
        "            dic[vector_strings[0]] = vector\n",
        "            # 將向量添加到列表中\n",
        "            vectors.append(vector)\n",
        "\n",
        "    return dic, np.array(vectors)\n",
        "\n",
        "def read_vectors_from_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BJQahi-4Vwp"
      },
      "outputs": [],
      "source": [
        "dic, vectors = read_vectors_from_file(\"/content/drive/MyDrive/datagame/hpe_all_ts.txt\")\n",
        "# 將song_id和歌手、作詞者、作曲者、發行人之類的資訊合併起來，用smore跑hpe，把song_id轉換成64個數字"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e102lfMFbVO"
      },
      "outputs": [],
      "source": [
        "dic_k = list(dic.keys())\n",
        "dic_v = list(dic.values())\n",
        "reverse_dic = {tuple(v): k for k, v in dic.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fdBWMAgD4O1"
      },
      "outputs": [],
      "source": [
        "train_source_df = read_vectors_from_csv(\"/content/drive/MyDrive/datagame/label_train_source.csv\")\n",
        "train_source_df.sort_values(by=['session_id', \"listening_order\"], inplace=True)\n",
        "train_source_df.reset_index(inplace=True, drop=True)\n",
        "train_target_df = read_vectors_from_csv(\"/content/drive/MyDrive/datagame/label_train_target.csv\")\n",
        "train_target_df.sort_values(by=['session_id', \"listening_order\"], inplace=True)\n",
        "train_target_df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptkNoEr4JSx3"
      },
      "outputs": [],
      "source": [
        "X = np.zeros( (len(train_source_df) // 20, 20, 64) )\n",
        "y = np.zeros( (len(train_target_df) // 5,  64 * 5) )\n",
        "\n",
        "for i in range(len(train_source_df)):\n",
        "    X[ i // 20 ][ i % 20 ] = dic[ train_source_df.loc[i, \"song_id\"] ]\n",
        "\n",
        "for i in range(len(train_target_df)):\n",
        "    y[ i // 5 ][ (i % 5) * 64 : (i % 5 + 1) * 64 ] = dic[ train_target_df.loc[i, \"song_id\"] ]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
        "del(X)\n",
        "del(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vKnaiJ5j08a"
      },
      "outputs": [],
      "source": [
        "modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/MyDrive/datagame/LSTM_simple.h5\",\n",
        "    monitor=\"val_loss\",verbose=0,save_best_only=True,\n",
        "    save_weights_only=True,mode=\"min\",)\n",
        "\n",
        "earlystop = keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,verbose=0,mode=\"min\")\n",
        "\n",
        "reduces = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                        factor=0.1,\n",
        "                        patience=5,\n",
        "                        verbose=1,\n",
        "                        mode='min',\n",
        "                        cooldown=1 )\n",
        "callbacks = [modelcheckpoint, reduces, earlystop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfB8h8XhDEMB",
        "outputId": "c29d0498-3b67-4fbf-f1ee-63248646c64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (Batch  (None, 20, 64)            256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20, 128)           8320      \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 20, 512)           788480    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 20, 1024)          4198400   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 512)               3147776   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 320)               164160    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8307392 (31.69 MB)\n",
            "Trainable params: 8307264 (31.69 MB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "act = 'tanh'\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(20, 64)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(128, activation=act),\n",
        "\n",
        "    # Bidirectional LSTM layers\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True, activation=act)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True, activation=act)),\n",
        "\n",
        "    # Final LSTM layer (unidirectional)\n",
        "    tf.keras.layers.LSTM(512, activation=act),\n",
        "    tf.keras.layers.Dense(320, activation=act)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Lion(learning_rate = 0.0001)\n",
        "model.compile(loss=\"mae\", optimizer=optimizer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-tWKx4INr5Rw",
        "outputId": "4f2406ee-495c-4ea2-8e2a-8c41781b676d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "503/503 [==============================] - 66s 114ms/step - loss: 0.0215 - val_loss: 0.0207 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0193 - val_loss: 0.0191 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0191 - val_loss: 0.0190 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0189 - val_loss: 0.0189 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0189 - val_loss: 0.0189 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0188 - val_loss: 0.0188 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0188 - val_loss: 0.0188 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "503/503 [==============================] - 55s 109ms/step - loss: 0.0187 - val_loss: 0.0187 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "503/503 [==============================] - 53s 106ms/step - loss: 0.0187 - val_loss: 0.0188 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0187 - val_loss: 0.0187 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "503/503 [==============================] - ETA: 0s - loss: 0.0186\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "503/503 [==============================] - 54s 106ms/step - loss: 0.0186 - val_loss: 0.0187 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "503/503 [==============================] - 55s 108ms/step - loss: 0.0185 - val_loss: 0.0186 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0185 - val_loss: 0.0186 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "503/503 [==============================] - 53s 106ms/step - loss: 0.0185 - val_loss: 0.0186 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "503/503 [==============================] - 54s 106ms/step - loss: 0.0185 - val_loss: 0.0186 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "503/503 [==============================] - 54s 108ms/step - loss: 0.0185 - val_loss: 0.0186 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "503/503 [==============================] - ETA: 0s - loss: 0.0185\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "503/503 [==============================] - 54s 106ms/step - loss: 0.0185 - val_loss: 0.0186 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "503/503 [==============================] - 55s 110ms/step - loss: 0.0184 - val_loss: 0.0186 - lr: 1.0000e-06\n",
            "Epoch 19/100\n",
            "503/503 [==============================] - 54s 107ms/step - loss: 0.0184 - val_loss: 0.0186 - lr: 1.0000e-06\n",
            "Epoch 20/100\n",
            "503/503 [==============================] - 54s 107ms/step - loss: 0.0184 - val_loss: 0.0186 - lr: 1.0000e-06\n",
            "Epoch 21/100\n",
            "503/503 [==============================] - 55s 108ms/step - loss: 0.0184 - val_loss: 0.0186 - lr: 1.0000e-06\n",
            "Epoch 22/100\n",
            "503/503 [==============================] - ETA: 0s - loss: 0.0184\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "503/503 [==============================] - 54s 106ms/step - loss: 0.0184 - val_loss: 0.0186 - lr: 1.0000e-06\n",
            "Epoch 23/100\n",
            "503/503 [==============================] - 54s 107ms/step - loss: 0.0184 - val_loss: 0.0186 - lr: 1.0000e-07\n",
            "Epoch 24/100\n",
            "503/503 [==============================] - 54s 107ms/step - loss: 0.0184 - val_loss: 0.0186 - lr: 1.0000e-07\n",
            "Epoch 25/100\n",
            "299/503 [================>.............] - ETA: 20s - loss: 0.0184"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cb37fc92e05e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(X_train, y_train, epochs=100, callbacks=callbacks, batch_size = 1024,\n\u001b[0m\u001b[1;32m      3\u001b[0m           validation_data=(X_test, y_test))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, callbacks=callbacks, batch_size = 1024,\n",
        "          validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm2tXUcBcFCX",
        "outputId": "b24ca9d0-9151-4b17-d295-e6c2eecefc6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "716/716 [==============================] - 4s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on test data\n",
        "predicted_target = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ucnP5aXpRv",
        "outputId": "ced4d258-fb10-40a4-e6de-cb1f551ba9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.048978284, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(sum(tf.keras.losses.mean_squared_error(y_test, predicted_target) ** 0.5) / len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTNQhEuWkX6t"
      },
      "source": [
        "# test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN_B6HL5jWNu"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "model.load_weights('/content/drive/MyDrive/datagame/LSTM_simple.h5')\n",
        "\n",
        "# Initialize the decoder input with zeros\n",
        "test_df = read_vectors_from_csv(\"/content/drive/MyDrive/datagame/label_test_source.csv\")\n",
        "test_df.sort_values(by=['session_id', \"listening_order\"], inplace=True)\n",
        "test_df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag5VVRKuSJ9Y"
      },
      "outputs": [],
      "source": [
        "X_result = np.zeros( (len(test_df) // 20, 20, 64) )\n",
        "test_session_id = []\n",
        "\n",
        "for i in range(len(test_df)):\n",
        "    X_result[ i // 20 ][ i % 20 ] = dic[ test_df.loc[i, \"song_id\"] ]\n",
        "    if i % 20 == 0:\n",
        "        test_session_id.append(test_df.loc[i, \"session_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhcEmUR5jfyu"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "already_used = []\n",
        "def find_closest_vector(target_vector):\n",
        "    # 計算與目標向量的距離\n",
        "    distances_squared = cp.sum((vectors - target_vector) ** 2, axis=1)\n",
        "    # 找出距離最近的 k 個向量的索引，並跳過已經出現過的vector\n",
        "    closest_index = cp.argmin(distances_squared)\n",
        "    while closest_index in already_used:\n",
        "      distances_squared[closest_index] = 9999999\n",
        "      closest_index = cp.argmin(distances_squared)\n",
        "\n",
        "    # 返回最近的 k 個向量\n",
        "    already_used.append(closest_index)\n",
        "    return vectors[closest_index]\n",
        "\n",
        "def find_key_by_value(value_to_find):\n",
        "    value_to_find = np.array(value_to_find.get())\n",
        "    value_tuple = tuple(value_to_find)\n",
        "    return reverse_dic.get(value_tuple, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1PHOauCeoh2",
        "outputId": "fc1d400e-ce15-4461-8bba-3b778b254cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4471/4471 [==============================] - 25s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predict the next vector for each sequence in the test set\n",
        "final_y = model.predict(X_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T42o4oUiiTr",
        "outputId": "69bf5a28-c14a-4d6d-d2fc-120a5a8da6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0%\n",
            "3.49%\n",
            "6.99%\n",
            "10.48%\n",
            "13.98%\n",
            "17.47%\n",
            "20.97%\n",
            "24.46%\n",
            "27.96%\n",
            "31.45%\n",
            "34.95%\n",
            "38.44%\n",
            "41.94%\n",
            "45.43%\n",
            "48.93%\n",
            "52.42%\n",
            "55.92%\n",
            "59.41%\n",
            "62.91%\n",
            "66.4%\n",
            "69.9%\n",
            "73.39%\n",
            "76.89%\n",
            "80.38%\n",
            "83.88%\n",
            "87.37%\n",
            "90.87%\n",
            "94.36%\n",
            "97.86%\n"
          ]
        }
      ],
      "source": [
        "# change vector to song id\n",
        "final_result = np.zeros(( len(test_session_id), 5)).astype(str)\n",
        "vectors = cp.array(vectors)\n",
        "final_y = cp.array(final_y)\n",
        "for i in range(len(test_session_id)):\n",
        "    if(i % 5000 == 0):\n",
        "      print(f\"{ str( round(i*100 / len(test_session_id), 2) ) }\" + \"%\")\n",
        "    already_used.clear()\n",
        "    for j in range(5):\n",
        "        final_result[i, j] = find_key_by_value( find_closest_vector( final_y[i, j*64 : (j+1)*64] ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQuWJirBXAaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14bc43c4-3367-48fa-8a01-0a1e858fa505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['bf96b92cf2afe619e4307bc972f8f0df',\n",
              "        '4f1f6db6a858baec3779db114eb6b985'],\n",
              "       ['b897d90f0c8989a40051950606edc798',\n",
              "        '32142bf5411ff50d0d6a795db5ff754c'],\n",
              "       ['6accb2b1efc3ef2e50c1b893ed84bc97',\n",
              "        '25dbafeee3fae51a805bdc73ab5051b1'],\n",
              "       ['822560a5231b62186417aa98da173d16',\n",
              "        '89840d06c35f2d25083be9e742d0d577'],\n",
              "       ['06de4491a1d215da9e7d69acae71f9b8',\n",
              "        '0e373df3c954f80a912a4c8ec05c2f44']], dtype='<U32')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "final_result[:5, :2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLPWCH6Kdo59"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "final_df = pd.DataFrame(columns=['session_id', 'top1', 'top2', 'top3', 'top4', 'top5'])\n",
        "final_df[\"session_id\"] = test_session_id\n",
        "final_df[\"top1\"] = final_result[:, 0]\n",
        "final_df[\"top2\"] = final_result[:, 1]\n",
        "final_df[\"top3\"] = final_result[:, 2]\n",
        "final_df[\"top4\"] = final_result[:, 3]\n",
        "final_df[\"top5\"] = final_result[:, 4]\n",
        "\n",
        "final_df.to_csv(\"/content/drive/MyDrive/datagame/LSTM_result.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}